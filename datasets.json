[{"_id":{"$oid":"67aa8d0a4af902a85137541a"},"dataset_num":1,"meta_features":[4000.0,8.294299608857235,25.0,3.258096538021482,3.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,25.0,0.0,1.0,0.00625,0.006230549750636074,160.0,5.081404364984463,0.33175,0.33475,0.3333333333333333,0.001230401921686119,1.5849526699006533,0.0,0.0,0.0,0.0,0.0,-0.04159309296748814,0.35994461716889736,0.09338040899155707,0.11149634770737475,-0.25875044328152536,0.0764054764015319,-0.0390143654798912,0.06710907009565864,19.0,-0.057454020803303724,0.311937811076449,0.641,0.4875,0.53925,0.56775,0.41275000000000006,0.531],"code":"\n# Generate a dataset with 5 classes\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nX, y = make_classification(\n    n_samples=4000,          # Number of samples\n    n_features=25,           # Total number of features\n    n_informative=10,        # Number of informative features\n    n_redundant=2,           # Number of redundant features\n    n_classes=3,             # Number of classes\n    n_clusters_per_class=2,  # Increase clusters per class for complexity\n    class_sep=0.5,           # Reduce class separation for overlap\n    flip_y=0.1,              # Introduce noise in labels\n    random_state=42          # Random state for reproducibility\n)\n\nnumpy_dataset = np.column_stack((X, y))\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d0a4af902a85137541b"},"dataset_num":2,"meta_features":[3000.0,8.006700845440367,20.0,3.044522437723423,2.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,20.0,0.0,1.0,0.006666666666666667,0.006644542718668579,150.0,5.017279836814924,0.49933333333333335,0.5006666666666667,0.5,0.0006666666666666765,0.9999987176040281,0.0,0.0,0.0,0.0,0.0,-0.19561385270116283,0.8869738464096102,0.08334775730767449,0.2574555291082772,-0.3523883090730235,0.5202486978720383,-0.029147348999867494,0.16864104492407128,15.0,-0.17101100903873825,0.35390645891817485,0.9410000000000001,0.8833333333333334,0.8736666666666666,0.8903333333333332,0.7283333333333333,0.8773333333333333],"code":"\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nX, y = make_classification(\n    n_samples=3000,\n    n_features=20,\n    n_informative=8,\n    n_redundant=2,\n    n_classes=2,\n    class_sep=1.0,\n    flip_y=0.01,\n    random_state=1\n)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d0b4af902a85137541c"},"dataset_num":3,"meta_features":[4000.0,8.294299608857235,25.0,3.258096538021482,3.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,25.0,0.0,1.0,0.00625,0.006230549750636074,160.0,5.081404364984463,0.331,0.33575,0.3333333333333333,0.0019400744544704597,1.584938067917734,0.0,0.0,0.0,0.0,0.0,-0.1645907299208007,0.48179527092820473,0.13452611885735588,0.1541564362099245,-0.11492599698742809,0.14559686856475584,-0.004165110705266775,0.061002916538579394,15.0,-0.12484692478482703,0.22248554489275607,0.6695,0.5112499999999999,0.5395000000000001,0.565,0.40525,0.5375],"code":"\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nX, y = make_classification(\n    n_samples=4000,\n    n_features=25,\n    n_informative=12,\n    n_redundant=3,\n    n_classes=3,\n    class_sep=0.5,\n    flip_y=0.1,\n    random_state=2\n)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d0b4af902a85137541d"},"dataset_num":4,"meta_features":[1000.0,6.90875477931522,100.0,4.61512051684126,4.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,100.0,0.0,1.0,0.1,0.09531017980432487,10.0,2.3978952727983707,0.246,0.255,0.25,0.0036742346141747707,1.999844343026231,0.0,0.0,0.0,0.0,0.0,-0.26263850376184505,0.917075048198408,0.055505329208824804,0.20244203338138442,-0.20979084558655117,0.21756430926560621,0.005541256273804988,0.08780665276118996,48.0,0.07082294954187829,0.027462143159820762,0.6050000000000001,0.505,0.5589999999999999,0.41500000000000004,0.296,0.351],"code":"\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# Dataset 3: High-dimensional data with few samples\nX, y = make_classification(\n    n_samples=1000,\n    n_features=100,\n    n_informative=20,\n    n_redundant=10,\n    n_classes=4,\n    class_sep=0.8,\n    flip_y=0.05,\n    random_state=3\n)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d0c4af902a85137541e"},"dataset_num":5,"meta_features":[5000.0,8.517393171418904,10.0,2.3978952727983707,5.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,10.0,0.0,1.0,0.002,0.001998002662673056,500.0,6.2166061010848646,0.197,0.204,0.2,0.0024754797514825217,2.321817740926739,0.0,0.0,0.0,0.0,0.0,-0.07348912514208372,1.3566254455048075,0.36880862518065133,0.3979809682397945,-0.19251473639215477,0.030168141507680428,-0.03967829158218198,0.06471842216472652,7.0,0.003488757639474663,0.4183888744207711,0.39840000000000003,0.23020000000000002,0.3006,0.38520000000000004,0.2326,0.3708],"code":"\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# Dataset : Low-dimensional with high overlap\nX, y = make_classification(\n    n_samples=5000,\n    n_features=10,\n    n_informative=5,\n    n_redundant=2,\n    n_classes=5,\n    class_sep=0.3,\n    flip_y=0.15,\n    random_state=4\n)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d0c4af902a85137541f"},"dataset_num":6,"meta_features":[4000.0,8.294299608857235,30.0,3.4339872044851463,3.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,30.0,0.0,1.0,0.0075,0.007472014838700995,133.33333333333334,4.9003242732785735,0.332,0.33525,0.3333333333333333,0.0013894443333777478,1.584949976931751,0.0,0.0,0.0,0.0,0.0,-0.275480034839501,0.4822478773577328,0.012782540177431967,0.1425414142955178,-0.23828932991726479,0.15784454849629295,-0.03493144542528155,0.09741919502371131,13.0,0.13893565541623776,0.114429306481453,0.8350000000000002,0.70625,0.7060000000000001,0.67925,0.45499999999999996,0.6669999999999999],"code":"\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# Dataset : Balanced classes with moderate complexity\nX, y = make_classification(\n    n_samples=4000,\n    n_features=30,\n    n_informative=15,\n    n_redundant=5,\n    n_classes=3,\n    weights=[0.33, 0.33, 0.34],  # Balanced class weights\n    class_sep=1.2,\n    flip_y=0.05,\n    random_state=5\n)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d0d4af902a851375420"},"dataset_num":7,"meta_features":[4000.0,8.294299608857235,20.0,3.044522437723423,3.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,20.0,0.0,1.0,0.005,0.004987541511039074,200.0,5.303304908059076,0.12525,0.66225,0.3333333333333333,0.2352909841498867,1.2439549977087787,0.0,0.0,0.0,0.0,0.0,-0.1487285501111093,0.8277572176942471,0.10708840657291918,0.2503240291548773,-0.3192195750380622,0.41023376464486083,-0.01746326373134065,0.14728805714428503,12.0,-0.20488381189764926,0.43549328323847636,0.7459999999999999,0.7745,0.733,0.68425,0.68125,0.67825],"code":"\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\n\nX, y = make_classification(\n    n_samples=4000,\n    n_features=20,\n    n_informative=8,\n    n_redundant=4,\n    n_classes=3,\n    weights=[0.7, 0.2, 0.1],  # Imbalanced class weights\n    class_sep=0.8,\n    flip_y=0.1,\n    random_state=6\n)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d0e4af902a851375421"},"dataset_num":8,"meta_features":[2000.0,7.601402334583733,50.0,3.9318256327243257,3.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,50.0,0.0,1.0,0.025,0.0246926125903715,40.0,3.713572066704308,0.332,0.335,0.3333333333333333,0.0012472191289246482,1.5849524066295575,0.0,0.0,0.0,0.0,0.0,-0.27077679312154324,0.3531772957843802,-0.03598459498612688,0.1275190835176994,-0.30290412152839225,0.2247683483281864,0.0043228060648286305,0.10890438701341575,23.0,-0.18225214597433723,-0.1974936410565049,0.9435,0.9305,0.9189999999999999,0.7665000000000001,0.49349999999999994,0.7329999999999999],"code":"\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\nX, y = make_classification(\n    n_samples=2000,\n    n_features=50,\n    n_informative=30,\n    n_redundant=5,\n    n_classes=3,\n    class_sep=2.0,  # Highly separable\n    flip_y=0.01,\n    random_state=8\n)\n\nnumpy_dataset = np.column_stack((X, y))\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d0e4af902a851375422"},"dataset_num":9,"meta_features":[569.0,6.345636360828596,30.0,3.4339872044851463,2.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,30.0,0.0,1.0,0.05272407732864675,0.05138116398911843,18.966666666666665,2.994064216453294,0.37258347978910367,0.6274165202108963,0.5,0.12741652021089633,0.9526351224018599,0.0,0.0,0.0,0.0,0.0,-0.5413670700179138,48.76719561050439,7.73570701103706,12.54773208167079,0.41433004572341553,5.432815862951928,1.7358152690860298,1.2539198138874432,0.0,1.746892477675132,3.7998873443658203,0.9051079024996118,0.9595870206489675,0.9385188635305075,0.915618692749573,0.8998447446048751,0.947290793355069],"code":"\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# Load Breast Cancer dataset\n\ndataset = load_breast_cancer()\nX = dataset.data\ny = dataset.target\nnumpy_dataset = np.column_stack((X, y))\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n\n"},{"_id":{"$oid":"67aa8d0e4af902a851375423"},"dataset_num":10,"meta_features":[178.0,5.187385805840755,13.0,2.639057329615259,3.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,13.0,0.0,1.0,0.07303370786516854,0.07048987775454472,13.692307692307692,2.687324070585093,0.2696629213483146,0.398876404494382,0.3333333333333333,0.05276780076256692,1.5668222768551812,0.0,0.0,0.0,0.0,0.0,-1.0896753288585077,2.0128060084773836,-0.02696467156011745,0.8731058884997415,-0.3046899289436044,1.0889148872106997,0.34721070556069833,0.4509786751853232,0.0,0.7607982379930838,-0.27607978619311524,0.7250793650793651,0.9717460317460318,0.9663492063492063,0.8709523809523809,0.6463492063492063,0.893015873015873],"code":"\nfrom sklearn.datasets import load_wine\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# Load Wine dataset\ndataset = load_wine()\nX = dataset.data\ny = dataset.target\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d0e4af902a851375424"},"dataset_num":11,"meta_features":[150.0,5.017279836814924,4.0,1.6094379124341003,3.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4.0,0.0,1.0,0.02666666666666667,0.02631730831737341,37.5,3.6506582412937387,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.0,1.584962500721156,0.0,0.0,0.0,0.0,0.0,-1.3955358863990055,0.1809763175224699,-0.781048730758266,0.6430747743869356,-0.2721276664567261,0.3157671063389326,0.06336457295472461,0.2575279634464968,1.0,-0.21754235746035136,-1.3711942730305884,0.96,0.9800000000000001,0.9533333333333334,0.9533333333333334,0.6666666666666666,0.9333333333333333],"code":"\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# Load iris dataset\ndataset = datasets.load_iris()\nX = dataset.data\ny = dataset.target\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d0e4af902a851375425"},"dataset_num":12,"meta_features":[1797.0,7.494430215031565,64.0,4.174387269895637,10.0,0.0,0.0,0.0,0.0,0.0,0.0,14.0,50.0,0.21875,0.78125,0.035614913745130775,0.03499536985869172,28.078125,3.369986173282579,0.09682804674457429,0.1018363939899833,0.1,0.0014521968114301505,3.3217753538402386,1.0,10.0,4.142857142857143,3.020339215980853,58.0,-1.6627718396447784,1792.0005567930025,109.8949685523192,317.86638263039004,-1.337858808644066,42.3556437419284,4.5226858722172425,9.24473022887949,28.0,0.16974725810723446,-0.6413123366545208,0.9643933766635715,0.9081832250077376,0.8069281956050759,0.7863447848963169,0.19754874651810586,0.7968956979263385],"code":"\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# Load Breast Cancer dataset\ndataset = datasets.load_digits()\nX = dataset.data\ny = dataset.target\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n\n"},{"_id":{"$oid":"67aa8d0f4af902a851375426"},"dataset_num":13,"meta_features":[5620.0,8.634264863002075,64.0,4.174387269895637,10.0,0.0,0.0,0.0,0.0,0.0,0.0,13.0,51.0,0.203125,0.796875,0.011387900355871887,0.011323546329254499,87.8125,4.486527405857319,0.09857651245551602,0.10177935943060498,0.09999999999999999,0.001150407820302107,3.3218327248667654,1.0,9.0,4.769230769230769,3.092269421883351,62.0,-1.6461227682222561,2805.0003559985726,168.40288026846537,481.80464955464134,-1.3026446521424488,52.98113207547163,5.449730608701149,11.212452959384446,41.0,-0.2610774081506443,0.41600886222316635,0.9736654804270461,0.9476868327402135,0.7272241992882563,0.88932384341637,0.19483985765124553,0.8909252669039146],"code":"\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport openml\n\ndataset = openml.datasets.get_dataset(dataset_id=28)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\n\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\n# Encode categorical columns\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n    \n# Step 4: Scale the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\ny = LabelEncoder().fit_transform(y)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d0f4af902a851375427"},"dataset_num":14,"meta_features":[1797.0,7.494430215031565,64.0,4.174387269895637,10.0,0.0,0.0,0.0,0.0,0.0,0.0,14.0,50.0,0.21875,0.78125,0.035614913745130775,0.03499536985869172,28.078125,3.369986173282579,0.09682804674457429,0.1018363939899833,0.1,0.0014521968114301505,3.3217753538402386,1.0,10.0,4.142857142857143,3.020339215980853,58.0,-1.6627718396447784,1792.0005567930025,109.8949685523192,317.86638263039004,-1.337858808644066,42.3556437419284,4.5226858722172425,9.24473022887949,28.0,0.16974725810723446,-0.6413123366545208,0.9643933766635715,0.9081832250077376,0.8069281956050759,0.785239863819251,0.19754874651810586,0.7963602599814299],"code":"\nfrom sklearn import datasets\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n# Load Digits Datasets\ndataset = datasets.load_digits()\nX = dataset.data\ny = dataset.target\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d104af902a851375428"},"dataset_num":15,"meta_features":[1309.0,7.177782416195197,7.0,2.0794415416798357,2.0,264.0,0.20168067226890757,2.0,0.2857142857142857,264.0,0.028811524609843937,5.0,2.0,0.7142857142857143,0.2857142857142857,0.0053475935828877,0.005333345975362581,187.0,5.236441962829949,0.3819709702062643,0.6180290297937356,0.5,0.11802902979373567,0.959422170862815,2.0,8.0,4.8,2.3151673805580453,24.0,-1.6381994613555715,26.920199499032726,9.283362394653496,11.861895389580287,-1.1152167275918492,4.362698924082934,1.422827970056456,2.2413742562809142,6.0,1.531203909712603,3.2913457159090234,0.6134977040741716,0.7318621859553684,0.7066040770963118,0.651639320288965,0.7799479395162471,0.5989470913398263],"code":"\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nimport openml\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\n# === Load Dataset ===\ndataset = openml.datasets.get_dataset(dataset_id=40945)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\n\n# === Encode Categorical Columns ===\nX[\"sex\"] = X[\"sex\"].map({\"male\": 1, \"female\": 0})  # Binary encoding\n\n# === Drop Non-Numeric Columns (Fix for String Conversion Error) ===\nX.drop(columns=[\"name\", \"ticket\", \"cabin\", \"boat\", \"body\", \"home.dest\"], inplace=True)\n\n# Encode \"embarked\" with most frequent catego\nX[\"embarked\"] = LabelEncoder().fit_transform(X[\"embarked\"])\n\n# === Convert to NumPy Arrays ===\nX = X.to_numpy(dtype=np.float32)  # Ensure numeric NumPy array\ny = y.to_numpy()\n\n# === Encode Labels if Needed ===\nif y.dtype.kind not in \"iu\":  # Convert non-integer labels to numeric\n    y = LabelEncoder().fit_transform(y)\n\n# === Standardize Features ===\nX = StandardScaler().fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d1f4af902a851375429"},"dataset_num":16,"meta_features":[10000.0,9.210440366976517,784.0,6.665683717782408,10.0,0.0,0.0,0.0,0.0,0.0,0.0,198.0,586.0,0.25255102040816324,0.7474489795918368,0.0784,0.07547846117590554,12.755102040816327,2.6214098128016805,0.0902,0.1125,0.1,0.005403702434442519,3.319843142675516,1.0,10.0,2.9545454545454546,2.828954646039421,585.0,-1.8206731917706553,9995.000100010035,1090.3691881223865,2599.071616898405,-0.2653747451390149,99.98499937495647,17.09540488216301,27.743276118723134,288.0,1.1748537033457862,1.3837599053253058,0.9105000000000001,0.5932999999999999,0.5515000000000001,0.7903,0.2023,0.7923000000000001],"code":"\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport openml\n\n    \ndataset = openml.datasets.get_dataset(dataset_id=554)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\ntarget_names = dataset.retrieve_class_labels() if dataset.retrieve_class_labels() else None\n\n# Limit dataset to top 10,000 samples if larger\nmax_samples = 10000\nif len(X) > max_samples:\n    X, _, y, _ = train_test_split(X, y, train_size=max_samples, stratify=y, random_state=42)\n\n# Encode categorical columns\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n\n# Step 4: Scale the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X=X)\ny = y.to_numpy()\n# === Encode Labels if Needed ===\nif y.dtype.kind not in \"iu\":  # Convert non-integer labels to numeric\n    y = LabelEncoder().fit_transform(y)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d274af902a85137542a"},"dataset_num":17,"meta_features":[5000.0,8.517393171418904,784.0,6.665683717782408,10.0,0.0,0.0,0.0,0.0,0.0,0.0,223.0,561.0,0.2844387755102041,0.7155612244897959,0.1568,0.14565757242236319,6.377551020408164,1.998441743488193,0.0902,0.1126,0.1,0.005427338205787438,3.3198257215330838,1.0,10.0,2.4663677130044843,2.272370364960228,550.0,-1.8200980171240604,4995.00020004001,551.4819349546033,1275.5634130971189,-0.269920406838098,70.68946314720469,12.600691026518044,19.437355276529303,260.0,1.2022504087005708,1.4777791009587373,0.89,0.41240000000000004,0.5366,0.7692,0.19339999999999996,0.7598],"code":"\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport openml\n\n    \ndataset = openml.datasets.get_dataset(dataset_id=554)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\ntarget_names = dataset.retrieve_class_labels() if dataset.retrieve_class_labels() else None\n\n# Limit dataset to 5,000 samples if larger\nmax_samples = 5000\nif len(X) > max_samples:\n    X, _, y, _ = train_test_split(X, y, train_size=max_samples, stratify=y, random_state=42)\n\n# Encode categorical columns\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n\n# Step 4: Scale the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X=X)\ny = y.to_numpy()\n# === Encode Labels if Needed ===\nif y.dtype.kind not in \"iu\":  # Convert non-integer labels to numeric\n    y = LabelEncoder().fit_transform(y)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d334af902a85137542b"},"dataset_num":18,"meta_features":[5000.0,8.517393171418904,784.0,6.665683717782408,10.0,0.0,0.0,0.0,0.0,0.0,0.0,10.0,774.0,0.012755102040816327,0.9872448979591837,0.1568,0.14565757242236319,6.377551020408164,1.998441743488193,0.1,0.1,0.1,0.0,3.321928094887362,3.0,10.0,7.2,2.749545416973504,72.0,-1.7329493096451094,4941.8514606035105,86.90702782215932,483.29179006549646,-0.8420586800910809,70.14636527136706,3.0664905179839197,8.498354663227365,228.0,0.16839294512440015,-0.95830097398288,0.7908000000000001,0.7862,0.5046,0.7283999999999999,0.19940000000000002,0.7218],"code":"\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport openml\n    \ndataset = openml.datasets.get_dataset(dataset_id=40996)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\ny = LabelEncoder().fit_transform(y)\nmax_samples = 5000\nif len(X) > max_samples:\n    X, _, y, _ = train_test_split(X, y, train_size=max_samples, stratify=y, random_state=1)\n\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X=X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d454af902a85137542c"},"dataset_num":19,"meta_features":[7000.0,8.853808274977197,784.0,6.665683717782408,10.0,0.0,0.0,0.0,0.0,0.0,0.0,8.0,776.0,0.01020408163265306,0.9897959183673469,0.112,0.10616019582839063,8.928571428571429,2.295416603515433,0.1,0.1,0.1,0.0,3.321928094887362,1.0,10.0,6.0,2.7838821814150108,48.0,-1.7445980047964549,6974.691968016992,85.86055588522603,504.9736515522024,-0.8719332869781862,83.46879449412653,3.0432386435621135,8.413674614779321,239.0,0.14798851726730644,-0.9966046680055687,0.8015714285714285,0.8029999999999999,0.5835714285714285,0.7368571428571429,0.19885714285714284,0.7434285714285714],"code":"\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport openml\nimport numpy as np\n    \ndataset = openml.datasets.get_dataset(dataset_id=40996)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\ny = LabelEncoder().fit_transform(y)\nmax_samples = 7000\nif len(X) > max_samples:\n    X, _, y, _ = train_test_split(X, y, train_size=max_samples, stratify=y, random_state=23)\n\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X=X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d454af902a85137542d"},"dataset_num":20,"meta_features":[10000.0,9.210440366976517,6.0,1.9459101490553132,2.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6.0,0.0,1.0,0.0006,0.0005998200719676155,1666.6666666666667,7.419180722820095,0.2393,0.7607,0.5,0.2607,0.7938742647538951,0.0,0.0,0.0,0.0,0.0,-0.14332435225296392,145.26623878893767,28.5715047668824,52.60179731712858,-0.2573978722335685,11.634501692261242,2.9855987300328475,4.167237204458234,0.0,1.2234106755560568,3.4849809680714214,0.7052999999999999,0.8015000000000001,0.7942000000000001,0.7638,0.8045,0.7594000000000001],"code":"\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nimport numpy as np\nimport openml\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# Step 1: Load the dataset\ndataset = openml.datasets.get_dataset(dataset_id=1590)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\ny = LabelEncoder().fit_transform(y)\n\n# Limit dataset to top 20,000 samples if larger\nmax_samples = 10000\nif len(X) > max_samples:\n    X, _, y, _ = train_test_split(X, y, train_size=max_samples, stratify=y, random_state=3)\n\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\n# Step 3: Encode categorical columns using OneHotEncoder\ncategorical_cols = X.select_dtypes(include='object').columns\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', 'passthrough', numeric_cols),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n    ]\n)\n\nX = preprocessor.fit_transform(X)\n\n# Step 5: Scale the features\nscaler = StandardScaler()\nX_test = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d454af902a85137542e"},"dataset_num":21,"meta_features":[3000.0,8.006700845440367,6.0,1.9459101490553132,2.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6.0,0.0,1.0,0.002,0.001998002662673056,500.0,6.2166061010848646,0.23933333333333334,0.7606666666666667,0.5,0.2606666666666667,0.7939298772580023,0.0,0.0,0.0,0.0,0.0,-0.009524911542892145,146.01419338955367,29.817161899682883,52.38475262811887,-0.28531476258274907,11.65869656813264,3.065884601775918,4.133837049219407,0.0,1.669963719091668,9.931735841102686,0.6983333333333334,0.7983333333333333,0.7896666666666666,0.7733333333333333,0.8076666666666666,0.7683333333333333],"code":"\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nimport openml\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# Step 1: Load the dataset\ndataset = openml.datasets.get_dataset(dataset_id=1590)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\ny = LabelEncoder().fit_transform(y)\n\n# Limit dataset to top 20,000 samples if larger\nmax_samples = 3000\nif len(X) > max_samples:\n    X, _, y, _ = train_test_split(X, y, train_size=max_samples, stratify=y, random_state=6)\n\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\n# Step 3: Encode categorical columns using OneHotEncoder\ncategorical_cols = X.select_dtypes(include='object').columns\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', 'passthrough', numeric_cols),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n    ]\n)\n\nX = preprocessor.fit_transform(X)\n\n# Step 5: Scale the features\nscaler = StandardScaler()\nX_test = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d464af902a85137542f"},"dataset_num":22,"meta_features":[10000.0,9.210440366976517,14.0,2.70805020110221,7.0,0.0,0.0,0.0,0.0,0.0,0.0,4.0,10.0,0.2857142857142857,0.7142857142857143,0.0014,0.001399020913707341,714.2857142857143,6.572682063274631,0.0121,0.4682,0.14285714285714285,0.17265607313916512,1.8696091420101681,2.0,2.0,2.0,0.0,8.0,-1.9477052989750616,15.418234070884495,2.5030303058558028,4.793422901479775,-1.1936296283397028,4.173515792576386,0.7938591573430142,1.5193064029471066,9.0,-0.5459631311673119,0.07268005315914383,0.6617,0.6546000000000001,0.483,0.6283999999999998,0.6092,0.6223],"code":"\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport openml\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# Step 1: Load the dataset\ndataset = openml.datasets.get_dataset(dataset_id=180)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\ny = LabelEncoder().fit_transform(y)\n\n# Limit dataset to top 10,000 samples if larger\nmax_samples = 10000\nif len(X) > max_samples:\n    X, _, y, _ = train_test_split(X, y, train_size=max_samples, stratify=y, random_state=42)\n\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\n# Encode categorical columns\ncategorical_cols = X.select_dtypes(include=\"object\").columns\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', 'passthrough', numeric_cols ),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n    ]\n)\n\nX = preprocessor.fit_transform(X)\n\n# Step 4: Scale the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d474af902a851375430"},"dataset_num":23,"meta_features":[2924.0,7.981049759665957,8.0,2.1972245773362196,105.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8.0,0.0,1.0,0.0027359781121751026,0.0027322421368729884,365.5,5.903998521326706,0.003761969904240766,0.2476060191518468,0.009523809523809525,0.024022154780508564,5.610425099240273,0.0,0.0,0.0,0.0,0.0,-1.3365139034371076,134.41075635770866,27.85865067015176,42.64263719558041,-0.3744416452371348,7.243641757159699,2.4826020501462907,2.372776047266725,3.0,4.052642423196676,43.85106250432165,0.22366584709050458,0.2585458377239199,0.20930628731998596,0.22435136400889827,0.247605666783749,0.2157967451118136],"code":"\nimport openml\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# Step 1: Load the dataset\ndataset = openml.datasets.get_dataset(dataset_id=537)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\ny = pd.Series(y, name = 'target')\n\nclass_counts = y.value_counts()\n# Step 3: Remove classes with fewer than 15 samples\nmin_samples_threshold = 15\nvalid_classes = class_counts[class_counts >= min_samples_threshold].index\nX = X[y.isin(valid_classes)]  \ny = y[y.isin(valid_classes)] \n\n\nX, _, y, _ = train_test_split(X, y, stratify=y, random_state=22)\n\n# Step 4: Preprocess the dataset\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\n# Encode categorical columns\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n\n# Step 6: Scale the features\nscaler = StandardScaler()\nX= scaler.fit_transform(X)\ny = LabelEncoder().fit_transform(y)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d494af902a851375431"},"dataset_num":24,"meta_features":[2000.0,7.601402334583733,66.0,4.204692619390966,3.0,1475.0,0.7375,42.0,0.6363636363636364,10546.0,0.07989393939393939,36.0,30.0,0.5454545454545454,0.45454545454545453,0.033,0.032467190137501496,30.303030303030305,3.4437149076531584,0.0545,0.657,0.3333333333333333,0.2480041442306067,1.1443174415857524,2.0,10.0,5.75,2.190573238015819,207.0,-1.8921947592620734,295.9488384892682,33.22466278344955,60.89742292067689,-2.956240570461791,17.0654457731561,3.245041645432942,4.368059945399694,47.0,1.3052563765094847,7.870633439410929,0.5734999999999999,0.688,0.3625,0.6749999999999999,0.657,0.6505],"code":"\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\nimport openml\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\ndataset = openml.datasets.get_dataset(dataset_id=42803)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\ny = LabelEncoder().fit_transform(y)\n\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\nmax_samples = 2000\nif len(X) > max_samples:\n    X, _, y, _ = train_test_split(X, y, train_size=max_samples, stratify=y, random_state=4)\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d4b4af902a851375432"},"dataset_num":25,"meta_features":[5000.0,8.517393171418904,66.0,4.204692619390966,3.0,3677.0,0.7354,44.0,0.6666666666666666,26432.0,0.0800969696969697,36.0,30.0,0.5454545454545454,0.45454545454545453,0.0132,0.013113639145383105,75.75757575757575,4.340652088535195,0.0546,0.657,0.3333333333333333,0.24797270459109452,1.1445577086214045,2.0,10.0,6.138888888888889,2.3112379772871336,221.0,-1.8727342755715894,306.16269552814634,33.976839020476675,63.83046150886112,-2.8610118575230143,17.348255412228006,3.2537445857791183,4.349673255666619,48.0,0.9953348079797785,5.022317899386161,0.6016,0.7148,0.3442,0.6746,0.6564,0.671],"code":"\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport openml\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\ndataset = openml.datasets.get_dataset(dataset_id=42803)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\ny = LabelEncoder().fit_transform(y)\n\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\nmax_samples = 5000\nif len(X) > max_samples:\n    X, _, y, _ = train_test_split(X, y, train_size=max_samples, stratify=y, random_state=4)\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d4e4af902a851375433"},"dataset_num":26,"meta_features":[10000.0,9.210440366976517,66.0,4.204692619390966,3.0,7361.0,0.7361,51.0,0.7727272727272727,52714.0,0.07986969696969697,35.0,31.0,0.5303030303030303,0.4696969696969697,0.0066,0.006578315360122567,151.5151515151515,5.02726394530988,0.0546,0.657,0.3333333333333333,0.24797270459109452,1.1445577086214045,3.0,10.0,6.257142857142857,2.4064539073423505,219.0,-1.8852668949498612,318.38015785492166,33.41435725475859,62.43763239873005,-2.8520747304354845,17.6334057595842,3.246110209387711,4.331097364480958,48.0,1.0371813899023374,5.452687997841446,0.6091,0.7142999999999999,0.4016,0.6948,0.657,0.6801],"code":"\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport openml\n\n\ndataset = openml.datasets.get_dataset(dataset_id=42803)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\ny = LabelEncoder().fit_transform(y)\n\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\nmax_samples = 10000\nif len(X) > max_samples:\n    X, _, y, _ = train_test_split(X, y, train_size=max_samples, stratify=y, random_state=4)\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d4f4af902a851375434"},"dataset_num":27,"meta_features":[3000.0,8.006700845440367,66.0,4.204692619390966,3.0,2218.0,0.7393333333333333,42.0,0.6363636363636364,15535.0,0.07845959595959597,36.0,30.0,0.5454545454545454,0.45454545454545453,0.022,0.02176149178151269,45.45454545454545,3.8384743174053337,0.05466666666666667,0.657,0.3333333333333333,0.24795175755391224,1.1447177120307728,2.0,10.0,6.0,2.273030282830976,216.0,-1.8780564211637072,265.4967802469133,31.874711271786467,57.406263565816396,-2.8336718735307223,16.246834593076024,3.199155655817361,4.244890682355539,48.0,1.164037582622399,6.248638040050192,0.575,0.6956666666666667,0.376,0.6713333333333333,0.6513333333333333,0.6323333333333334],"code":"\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport openml\n\n\ndataset = openml.datasets.get_dataset(dataset_id=42803)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\ny = LabelEncoder().fit_transform(y)\n\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\nmax_samples = 3000\nif len(X) > max_samples:\n    X, _, y, _ = train_test_split(X, y, train_size=max_samples, stratify=y, random_state=4)\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d4f4af902a851375435"},"dataset_num":28,"meta_features":[403.0,6.0014148779611505,5.0,1.791759469228055,5.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5.0,0.0,1.0,0.01240694789081886,0.01233061245747872,80.6,4.401829261970061,0.05955334987593052,0.3200992555831266,0.2,0.11478512318052436,2.0471020615246407,0.0,0.0,0.0,0.0,0.0,-1.1994071006774902,-0.17828130722045898,-0.7728052139282227,0.41379231214523315,0.019226133823394775,0.6947489976882935,0.3910114526748657,0.2534373284831716,4.0,0.1485738903284073,-0.4761512279510498,0.7668209876543209,0.9157098765432099,0.8387345679012345,0.8511419753086418,0.5311419753086419,0.8414506172839505],"code":"\nimport numpy as np\nimport openml\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import TensorDataset, DataLoader\n# === Step 1: Load the dataset ===\ndataset = openml.datasets.get_dataset(dataset_id=1508)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\n\n# === Ensure X is a NumPy array ===\nX = np.array(X, dtype=np.float32)\n\ny = y.to_numpy(dtype=np.float32) - 1\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d4f4af902a851375436"},"dataset_num":29,"meta_features":[270.0,5.602118820879701,13.0,2.639057329615259,2.0,0.0,0.0,0.0,0.0,0.0,0.0,8.0,5.0,0.6153846153846154,0.38461538461538464,0.04814814814814815,0.04702493864486287,20.76923076923077,3.080497540181701,0.4444444444444444,0.5555555555555556,0.5,0.05555555555555558,0.9910760598382222,2.0,4.0,2.875,0.7806247497997998,23.0,-1.9905537078237758,4.783267722762652,0.09088352304310253,1.8136080771118361,-0.8738777328830319,1.98088693354221,0.4245873990611556,0.8344650179808736,11.0,0.2973341810454454,-0.7791224569353972,0.7777777777777778,0.8407407407407408,0.8407407407407408,0.737037037037037,0.7222222222222223,0.762962962962963],"code":"\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OrdinalEncoder\nimport numpy as np\nimport openml\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n# Step 1: Load dataset\ndataset = openml.datasets.get_dataset(dataset_id=53)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\n\n# Encode target labels\ny = LabelEncoder().fit_transform(y)\n\n# Step 2: Handle missing values (only numerical columns)\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\n# **Identify categorical columns more robustly**\ncategorical_cols = X.select_dtypes(include=['object', 'category']).columns \n\nif len(categorical_cols) > 0:\n    X[categorical_cols] = OrdinalEncoder().fit_transform(X[categorical_cols])\n\n# Step 4: Convert to NumPy array and Scale features\nX = X.astype(np.float32)  # ✅ Ensures all values are numeric\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d504af902a851375437"},"dataset_num":30,"meta_features":[8000.0,8.987321812850125,51.0,3.9512437185814275,2.0,0.0,0.0,0.0,0.0,0.0,0.0,44.0,7.0,0.8627450980392157,0.13725490196078433,0.006375,0.006354765638007765,156.86274509803923,5.061725953575655,0.117,0.883,0.5,0.383,0.5206755312572333,2.0,2.0,2.0,0.0,88.0,-1.9955059565598268,3539.0661425380376,91.71462234443348,488.96927866511606,-7.472671771843538,50.27809721245782,4.132535656089898,7.4260591160675045,36.0,-0.17760214785749268,-0.2592699678251611,0.866625,0.8977499999999999,0.8605,0.870125,0.883,0.8636250000000001],"code":"\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nimport openml\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# === Step 1: Load the dataset ===\ndataset = openml.datasets.get_dataset(dataset_id=1461)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\n# Limit dataset to top 8,000 samples if larger\nmax_samples = 8000\nif len(X) > max_samples:\n    X, _, y, _ = train_test_split(X, y, train_size=max_samples, stratify=y, random_state=42)\ny = LabelEncoder().fit_transform(y)  # Convert labels to numeric\n\nfor col in X.columns:\n    if X[col].dtype == \"object\" or X[col].dtype.name == \"category\":\n        X[col] = X[col].astype(str)\n\ncategorical_cols = X.select_dtypes(include=['object']).columns.tolist()\nnumeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\nif categorical_cols: \n    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n    encoded_cats = encoder.fit_transform(X[categorical_cols])\n    X = X.drop(columns=categorical_cols)\n    X = np.hstack((encoded_cats, X.to_numpy())) \nelse:\n    X = X.to_numpy()\n\nX = np.array(X, dtype=np.float32)\nX = StandardScaler().fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d514af902a851375438"},"dataset_num":31,"meta_features":[10000.0,9.210440366976517,8.0,2.1972245773362196,2.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,7.0,0.125,0.875,0.0008,0.0007996801705643322,1250.0,7.1316985104669115,0.4245,0.5755,0.5,0.07550000000000001,0.9834894750387236,7.0,7.0,7.0,0.0,7.0,-1.3218149360672908,4535.078551726921,588.135066045554,1492.8900886446916,-0.18624895380565065,66.08069742296186,9.525202448992001,21.60131060409698,6.0,0.2760846718775804,5.506207794694621,0.7756,0.7319,0.7039000000000001,0.8135999999999999,0.7561,0.7746],"code":"\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport openml\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# Step 1: Load the dataset\n\ndataset = openml.datasets.get_dataset(dataset_id=151)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\n\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y)\n\n# Limit dataset to top 10,000 samples if larger\nmax_samples = 10000\nif len(X) > max_samples:\n    X, _, y, _ = train_test_split(X, y, train_size=max_samples, stratify=y, random_state=42)\n\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n    \n\n# Step 4: Scale the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d544af902a851375439"},"dataset_num":32,"meta_features":[45312.0,10.72134924601891,8.0,2.1972245773362196,2.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,7.0,0.125,0.875,0.00017655367231638418,0.00017653808855100034,5664.0,8.642062173462106,0.4245453742937853,0.5754546257062146,0.5,0.07545462570621467,0.9835093906057095,7.0,7.0,7.0,0.0,7.0,-1.3181243702493421,7046.996485449295,900.2686319437553,2323.828244660828,-0.16580903665132246,78.68440206128668,11.040334644698204,25.736535147194072,6.0,0.41044837102509324,7.9683828401950585,0.6760656546429584,0.6935243043417623,0.7348804086103377,0.65165857195273,0.7541904917131126,0.6539969739764949],"code":"\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport openml\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\n# Step 1: Load the dataset\n\ndataset = openml.datasets.get_dataset(dataset_id=151)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\n\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y)\n\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n    \n\n# Step 4: Scale the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d544af902a85137543a"},"dataset_num":33,"meta_features":[2310.0,7.745435610274381,16.0,2.833213344056216,7.0,0.0,0.0,0.0,0.0,0.0,0.0,2.0,14.0,0.125,0.875,0.006926406926406926,0.00690252956277051,144.375,4.979316610838828,0.14285714285714285,0.14285714285714285,0.14285714285714282,2.7755575615628914E-17,2.807354922057604,3.0,4.0,3.5,0.5,7.0,-0.5201251435576926,338.4846980608378,43.35813891234818,94.17386781654653,-0.8847858284737401,16.88995864143604,3.7238122131675375,4.8485482697170665,7.0,0.8409348665368964,-0.49063166586166407,0.8956709956709956,0.8367965367965369,0.7121212121212123,0.9034632034632034,0.28484848484848485,0.9021645021645022],"code":"\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport openml\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\ndataset = openml.datasets.get_dataset(dataset_id=40984)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y)\n\n# Step 2: Preprocess the dataset\n# Fill missing values only for numerical columns\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\n# Encode categorical columns\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n    \n# Step 4: Scale the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d564af902a85137543b"},"dataset_num":34,"meta_features":[6178.0,8.72891172506098,29.0,3.4011973816621555,2.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,29.0,0.0,1.0,0.0046940757526707675,0.004683092935125707,213.0344827586207,5.366137136427179,0.07963742311427646,0.9203625768857235,0.5,0.42036257688572354,0.4009003378520911,0.0,0.0,0.0,0.0,0.0,0.17520580485616843,520.230092066217,58.63820409558026,104.95324421985649,-6.949994572709863,8.48111057494272,-0.9983778442775285,3.8078948604906477,0.0,7.999503439008819,111.30322190169395,0.9741021710362538,0.9789575881451201,0.9608289768483944,0.9736159480104293,0.9787955138031785,0.971672759194476],"code":"\nimport openml\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# === Step 1: Load the dataset ===\ndataset = openml.datasets.get_dataset(dataset_id=1597)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\n\n# Convert target variable (y) to numeric\ny = LabelEncoder().fit_transform(y)  # Convert labels to 0 (non-fraud) & 1 (fraud)\n\n# Step 2: Filter Fraud and Non-Fraud Transactions\nfraud_idx = np.where(y == 1)[0]  # Indices of fraud transactions\nnon_fraud_idx = np.where(y == 0)[0]  # Indices of non-fraud transactions\n\n# Randomly sample 5% of non-fraud transactions\nnp.random.seed(42)\nsampled_non_fraud_idx = np.random.choice(non_fraud_idx, size=int(0.02 * len(non_fraud_idx)), replace=False)\n\n# Combine fraud and sampled non-fraud transactions\nselected_idx = np.concatenate([fraud_idx, sampled_non_fraud_idx])\n\nX = X.iloc[selected_idx]\ny = y[selected_idx]\n\n# Step 3: Preprocessing\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\n# Encode categorical columns\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n\n# Convert X to a NumPy array before passing to feature extractor\nX = np.array(X, dtype=np.float32)\n\n# Step 5: Scale Features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d574af902a85137543c"},"dataset_num":35,"meta_features":[1913.0,7.5569505720129,29.0,3.4011973816621555,2.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,29.0,0.0,1.0,0.015159435441714584,0.015045679411017344,65.96551724137932,4.204177818864796,0.25718766335598536,0.7428123366440146,0.5,0.2428123366440146,0.8224727949426118,0.0,0.0,0.0,0.0,0.0,0.01781693429894826,182.9298242962373,20.78830095183984,37.713305568922806,-7.920522063794644,5.299010699821666,-0.9967447837421592,2.753534313959817,0.0,4.658149425586318,27.92965282686698,0.9210695391849958,0.9241972304621819,0.9377892909381706,0.9362363812830642,0.9430084890571816,0.9341325714598172],"code":"\nimport openml\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# === Step 1: Load the dataset ===\ndataset = openml.datasets.get_dataset(dataset_id=1597)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\n\n# Convert target variable (y) to numeric\ny = LabelEncoder().fit_transform(y)  # Convert labels to 0 (non-fraud) & 1 (fraud)\n\n# Step 2: Filter Fraud and Non-Fraud Transactions\nfraud_idx = np.where(y == 1)[0]  # Indices of fraud transactions\nnon_fraud_idx = np.where(y == 0)[0]  # Indices of non-fraud transactions\n\n# Randomly sample 5% of non-fraud transactions\nnp.random.seed(42)\nsampled_non_fraud_idx = np.random.choice(non_fraud_idx, size=int(0.005 * len(non_fraud_idx)), replace=False)\n\n# Combine fraud and sampled non-fraud transactions\nselected_idx = np.concatenate([fraud_idx, sampled_non_fraud_idx])\n\nX = X.iloc[selected_idx]\ny = y[selected_idx]\n\n# Step 3: Preprocessing\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\n# Encode categorical columns\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n\n# Convert X to a NumPy array before passing to feature extractor\nX = np.array(X, dtype=np.float32)\n\n# Step 5: Scale Features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X)\n\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d584af902a85137543d"},"dataset_num":36,"meta_features":[380.0,5.942799375126701,1247.0,7.129297548929373,2.0,0.0,0.0,0.0,0.0,0.0,0.0,1218.0,29.0,0.9767441860465116,0.023255813953488372,3.281578947368421,1.4543218544986063,0.30473135525260625,0.2659971615390013,0.24473684210526317,0.7552631578947369,0.5,0.25526315789473686,0.8028291415178707,1.0,8.0,2.006568144499179,0.22913318282446513,2444.0,-1.6645310762474153,375.0026385224429,349.81929765415333,86.31551836394715,-1.4023869808296416E-17,19.416555784238238,18.402462734628024,3.6207772668259923,351.0,0.045575794283696194,-0.58636614591193,0.24473684210526314,0.7552631578947369,0.25526315789473686,0.763157894736842,0.8184210526315789,0.7973684210526316],"code":"\nimport openml\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# === Step 1: Load the dataset ===\ndataset = openml.datasets.get_dataset(dataset_id=42195)\nX, _, _, _ = dataset.get_data(target=None, dataset_format=\"dataframe\")  # No default target\ny = X[\"home_team_goal\"] - X[\"away_team_goal\"]\ny = np.where(y > 0, 1, np.where(y < 0, -1, 0))  # Convert to Win/Loss/Draw classification\n# Step 2: Preprocessing\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())  # Fill missing values\n\ncategorical_cols = X.select_dtypes(include=['object']).columns.tolist()\nif categorical_cols:\n    preprocessor = ColumnTransformer(\n        transformers=[('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)],\n        remainder=\"passthrough\"\n    )\n    X = preprocessor.fit_transform(X)\n\n# Convert `X` to NumPy array\nX = np.array(X, dtype=np.float32)\n\n# Step 4: Scale the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d5a4af902a85137543e"},"dataset_num":37,"meta_features":[19020.0,9.85329891095284,10.0,2.3978952727983707,2.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,10.0,0.0,1.0,0.0005257623554153522,0.000525624190813876,1902.0,7.551186867296149,0.3516298633017876,0.6483701366982124,0.5,0.14837013669821242,0.9355152445467361,0.0,0.0,0.0,0.0,0.0,-0.533878754124272,16.760684257499975,4.271720920950255,5.348678960123032,-1.122989482519833,3.371362073689997,0.6462939807930795,1.2594770815849408,6.0,0.580354847815749,0.23251429953177105,0.8162460567823343,0.7847528916929548,0.7269716088328075,0.8190325972660359,0.7312302839116719,0.8034700315457414],"code":"\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport openml\nimport numpy as np\ndataset = openml.datasets.get_dataset(dataset_id=1120)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y)\n\n\n# Step 2: Preprocess the dataset\n# Fill missing values only for numerical columns\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\n# Encode categorical columns\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n\n\n# Step 4: Scale the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d5b4af902a85137543f"},"dataset_num":38,"meta_features":[1000.0,6.90875477931522,10.0,2.3978952727983707,2.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,10.0,0.0,1.0,0.01,0.009950330853168083,100.0,4.61512051684126,0.5,0.5,0.5,0.0,1.0,0.0,0.0,0.0,0.0,0.0,-0.08126471415042236,0.5511107040259198,0.3123715371696246,0.2009972149811852,-0.2667107627947537,0.29829780748287854,-0.032808687035584254,0.14687181565101817,6.0,0.056072479028879796,0.6054391433942836,0.807,0.7129999999999999,0.7150000000000001,0.737,0.606,0.718],"code":"\nfrom sklearn.datasets import make_classification\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nX , y = make_classification(\n    n_samples=1000, \n    n_features=10, \n    n_informative=7, \n    n_redundant=2, \n    n_classes=2, \n    n_clusters_per_class=2, \n    class_sep=0.6, \n    flip_y=0.05, \n    random_state=1)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d5b4af902a851375440"},"dataset_num":39,"meta_features":[2000.0,7.601402334583733,20.0,3.044522437723423,3.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,20.0,0.0,1.0,0.01,0.009950330853168083,100.0,4.61512051684126,0.325,0.349,0.3333333333333333,0.011085526098877243,1.5841706903629467,0.0,0.0,0.0,0.0,0.0,-0.1986179037869702,0.6729467620905103,0.15757121774384525,0.21825367356184408,-0.34448450430289335,0.34744631426668565,0.015786359717317143,0.1415142758042636,11.0,0.07619827153068864,0.2884772067652861,0.621,0.541,0.5654999999999999,0.5615,0.441,0.523],"code":"\nfrom sklearn.datasets import make_classification\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nX , y = make_classification(\n    n_samples=2000, \n    n_features=20, \n    n_informative=9, \n    n_redundant=4, \n    n_classes=3, \n    n_clusters_per_class=3, \n    class_sep=0.7, \n    flip_y=0.1, \n    random_state=2)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d5c4af902a851375441"},"dataset_num":40,"meta_features":[3000.0,8.006700845440367,45.0,3.828641396489095,5.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,45.0,0.0,1.0,0.015,0.014888612493750654,66.66666666666667,4.214593690373678,0.19666666666666666,0.209,0.2,0.0045655716448703785,2.3215560852242465,0.0,0.0,0.0,0.0,0.0,-0.20170133460338846,0.3424586776115284,0.05607939544684548,0.10162198838662757,-0.11886632669791433,0.12320853760940757,0.003956551974063521,0.06083710796283475,19.0,-0.09180658020437826,0.06277715627866964,0.45899999999999996,0.363,0.429,0.34199999999999997,0.219,0.32433333333333336],"code":"\nfrom sklearn.datasets import make_classification\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nX, y = make_classification(\n    n_samples=3000, \n    n_features=45, \n    n_informative=30, \n    n_redundant=10, \n    n_classes=5, \n    n_clusters_per_class=1, \n    class_sep=0.4, \n    flip_y=0.2, \n    random_state=3)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d5c4af902a851375442"},"dataset_num":41,"meta_features":[4000.0,8.294299608857235,25.0,3.258096538021482,4.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,25.0,0.0,1.0,0.00625,0.006230549750636074,160.0,5.081404364984463,0.247,0.25525,0.25,0.003127499000799192,1.9998875441506967,0.0,0.0,0.0,0.0,0.0,-0.14802072638871078,1.0977221594737987,0.16359129340924716,0.2377143299305744,-0.12431674602449128,0.13168042082245734,0.00249375957581621,0.057770480903222655,12.0,0.03521696814585604,0.5190706962687361,0.48774999999999996,0.35649999999999993,0.37100000000000005,0.35025,0.281,0.34725],"code":"\nfrom sklearn.datasets import make_classification\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nX, y = make_classification(n_samples=4000, \n                    n_features=25, \n                    n_informative=12, \n                    n_redundant=5, \n                    n_classes=4, \n                    n_clusters_per_class=4, \n                    class_sep=0.5, \n                    flip_y=0.15, \n                    random_state=4)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)                    \n"},{"_id":{"$oid":"67aa8d5f4af902a851375443"},"dataset_num":42,"meta_features":[5000.0,8.517393171418904,100.0,4.61512051684126,6.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,100.0,0.0,1.0,0.02,0.019802627296179712,50.0,3.9318256327243257,0.1636,0.169,0.16666666666666666,0.0017307673314329607,2.584884560923302,0.0,0.0,0.0,0.0,0.0,-0.13744720819239875,0.21962549303230894,0.03482803355799664,0.0800450097409436,-0.08013483541919224,0.0934520882765944,0.005728895113122764,0.03338090495799584,41.0,-0.003675288006899811,0.17448663489348348,0.2612,0.36639999999999995,0.3618,0.21739999999999998,0.19740000000000002,0.21800000000000003],"code":"\nfrom sklearn.datasets import make_classification\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nX, y = make_classification(n_samples=5000, \n                    n_features=100, \n                    n_informative=80, \n                    n_redundant=20, \n                    n_classes=6, \n                    n_clusters_per_class=3, \n                    class_sep=0.8, \n                    flip_y=0.05, \n                    random_state=5)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8d944af902a851375444"},"dataset_num":43,"meta_features":[8000.0,8.987321812850125,600.0,6.398594934535208,12.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,600.0,0.0,1.0,0.075,0.07232066157962612,13.333333333333334,2.662587827025453,0.08125,0.084875,0.08333333333333336,0.0011125858269015584,3.5848336961878386,0.0,0.0,0.0,0.0,0.0,-0.14866041097792593,0.1946941601354757,0.007447801079299208,0.054954944699401015,-0.09208311454653054,0.07008932925033494,-0.0015753129598309965,0.02752122259264768,106.0,-0.03406863221970176,0.10512383687553761,0.10375000000000001,0.109125,0.113125,0.08212499999999999,0.08449999999999999,0.089],"code":"\nfrom sklearn.datasets import make_classification\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nX, y = make_classification(n_samples=8000, \n                    n_features=600, \n                    n_informative=400, \n                    n_redundant=120, \n                    n_classes=12, \n                    n_clusters_per_class=4, \n                    class_sep=0.5, \n                    flip_y=0.2, \n                    random_state=8)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8dd44af902a851375445"},"dataset_num":44,"meta_features":[10000.0,9.210440366976517,400.0,5.993961427306569,20.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,400.0,0.0,1.0,0.04,0.039220713153281295,25.0,3.258096538021482,0.0466,0.0537,0.05,0.0018036074961032959,4.320992476209998,0.0,0.0,0.0,0.0,0.0,-0.13785819274596944,0.13991488868405755,-0.0007566999774309447,0.04794542204721063,-0.06997266307242792,0.06994777638795624,-0.0017585388240213451,0.023282048216046177,216.0,0.02284900460824082,0.10702768820540554,0.0477,0.0655,0.0623,0.0501,0.0536,0.05550000000000001],"code":"\nfrom sklearn.datasets import make_classification\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nX, y = make_classification(n_samples=10000, \n                    n_features=400, \n                    n_informative=300, \n                    n_redundant=10, \n                    n_classes=20, \n                    n_clusters_per_class=5, \n                    class_sep=0.4, \n                    flip_y=0.3, \n                    random_state=10)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8ddf4af902a851375446"},"dataset_num":45,"meta_features":[8000.0,8.987321812850125,200.0,5.303304908059076,8.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,200.0,0.0,1.0,0.025,0.0246926125903715,40.0,3.713572066704308,0.121,0.129875,0.125,0.0025988278607864705,2.999688704240971,0.0,0.0,0.0,0.0,0.0,-0.1428016072806786,0.21281779990045857,0.010085612057081264,0.05919601619278957,-0.064442486330876,0.07088547241077692,0.0005236899124570052,0.02738654845610574,123.0,-0.0004222249846963288,-0.014785626192079793,0.15337499999999998,0.16774999999999998,0.17800000000000002,0.148125,0.132125,0.15075],"code":"\nfrom sklearn.datasets import make_classification\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nX, y = make_classification(n_samples=8000, \n                    n_features=200, \n                    n_informative=180, \n                    n_redundant=10, \n                    n_classes=8, \n                    n_clusters_per_class=2, \n                    class_sep=0.3, \n                    flip_y=0.25, random_state=6)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8ddf4af902a851375447"},"dataset_num":46,"meta_features":[5000.0,8.517393171418904,21.0,3.091042453358316,3.0,0.0,0.0,0.0,0.0,0.0,0.0,6.0,15.0,0.2857142857142857,0.7142857142857143,0.0042,0.004191204618468071,238.0952380952381,5.476861958311282,0.3298,0.3382,0.3333333333333333,0.003556527644893108,1.584880529042533,2.0,2.0,2.0,0.0,12.0,-1.5661778111674143,6.383894794355518,0.07493701227007074,1.5581333832178308,-0.6586517963481048,2.895495604271489,0.24574419966653208,0.7048081562964876,9.0,-0.029882195637784464,0.26633402006177054,0.7630000000000001,0.7323999999999999,0.6721999999999999,0.7550000000000001,0.502,0.7415999999999999],"code":"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import make_classification\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# Step 1: Generate Numerical Data\nX, y = make_classification(\n    n_samples=5000, n_features=15, n_informative=10, n_redundant=3, \n    n_classes=3, n_clusters_per_class=2, class_sep=0.7, flip_y=0.1, random_state=42\n)\n\n# Step 2: Convert to DataFrame\ndf = pd.DataFrame(X, columns=[f\"num_feature_{i}\" for i in range(X.shape[1])])\n\n# Step 3: Generate Categorical Features With Some Randomness\nnp.random.seed(42)\n\n# ✅ FIX: Ensure choices and default value have the same dtype (string)\ndf[\"category_1\"] = np.select(\n    [y == 0, y == 1, y == 2],  # Conditions\n    [np.random.choice([\"A\", \"B\"], size=len(y)),  \n     np.random.choice([\"B\", \"C\"], size=len(y)),  \n     np.random.choice([\"C\", \"A\"], size=len(y))],\n    default=\"Unknown\"  # Ensure the default is also a string\n)\n\ndf[\"category_2\"] = np.select(\n    [df[\"num_feature_1\"] > df[\"num_feature_1\"].median(), y == 0],\n    [np.random.choice([\"High\", \"Medium\"], size=len(y)), \n     np.random.choice([\"Low\", \"Medium\"], size=len(y))],\n    default=\"Medium\"  # Ensure the default is also a string\n)\n\n# Step 4: Encode Categorical Features\nencoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\nencoded_cats = encoder.fit_transform(df[[\"category_1\", \"category_2\"]])\n\n# Step 5: Convert Encoded Data to DataFrame\ncat_columns = encoder.get_feature_names_out([\"category_1\", \"category_2\"])\ndf_encoded = pd.DataFrame(encoded_cats, columns=cat_columns)\n\n# Step 6: Merge Encoded Features and Drop Raw Categorical Columns\ndf_final = pd.concat([df.drop(columns=[\"category_1\", \"category_2\"]), df_encoded], axis=1)\n\n# Convert `df_final` (features) to NumPy array\nX = df_final.to_numpy(dtype=np.float32)\n\n# Ensure `y` is a NumPy array\ny = np.array(y, dtype=np.int32)  # Use int type for classification labels\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8de04af902a851375448"},"dataset_num":47,"meta_features":[20000.0,9.90353755128617,16.0,2.833213344056216,26.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,16.0,0.0,1.0,0.0008,0.0007996801705643322,1250.0,7.1316985104669115,0.0367,0.04065,0.03846153846153846,0.0011362309228581885,4.699810726573158,0.0,0.0,0.0,0.0,0.0,-0.4213735197821413,2.074426286210775,0.6972634932639143,0.6707507427583589,-0.3100558134579747,1.1598880154846973,0.2902752613706473,0.45519639027932696,11.0,0.033800326028443115,-0.38820773072054005,0.9522999999999999,0.7013999999999999,0.64305,0.8753,0.07179999999999999,0.8560000000000001],"code":"\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport openml\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\n# Step 1: Load the dataset\n\ndataset = openml.datasets.get_dataset(dataset_id=6)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y)\n# Step 2: Preprocess the dataset\n# Fill missing values only for numerical columns\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\n# Encode categorical columns\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n    \n# Step 4: Scale the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8de44af902a851375449"},"dataset_num":48,"meta_features":[58000.0,10.968215530759236,9.0,2.302585092994046,7.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,9.0,0.0,1.0,0.00015517241379310346,0.00015516037579939586,6444.444444444444,8.771128872568136,0.00017241379310344826,0.7859655172413793,0.14285714285714285,0.26769631350816964,0.9603013611073694,0.0,0.0,0.0,0.0,0.0,0.5434470207623385,7697.561118271752,1817.493431640947,2833.829696435352,-21.861245025486685,31.687033807279462,2.368802659269136,12.851897537827897,5.0,2.241857257638867,9.293362408060416,0.9989137931034484,0.9438275862068967,0.7360172413793103,0.9997931034482758,0.868948275862069,0.9993620689655174],"code":"\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport openml\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\n# Step 1: Load the dataset\n\ndataset = openml.datasets.get_dataset(dataset_id=40685)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\n\n# Step 2: Preprocess the dataset\n# Fill missing values only for numerical columns\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\n# Encode categorical columns\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n\n\n# Step 4: Scale the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\ny = LabelEncoder().fit_transform(y)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8de54af902a85137544a"},"dataset_num":49,"meta_features":[4601.0,8.434246270595311,57.0,4.060443010546419,2.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,57.0,0.0,1.0,0.01238861117148446,0.012312500288817708,80.71929824561404,4.403290182609736,0.39404477287546186,0.6059552271245382,0.5,0.10595522712453817,0.9673602371807666,0.0,0.0,0.0,0.0,0.0,5.2503790081410475,1479.0321922910546,240.90671025613486,294.30154261178177,1.591155310295409,31.05193662927832,11.182991741438656,6.895040257896879,47.0,8.149649947883125,88.40737861975624,0.877632063447104,0.8795933059528867,0.8222062502950479,0.8815436906953689,0.7750502761648491,0.8667608459613841],"code":"\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport openml\nfrom sklearn.model_selection import train_test_split\ndataset = openml.datasets.get_dataset(dataset_id=44)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\n\n# Step 4: Scale the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\ny = LabelEncoder().fit_transform(y)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"},{"_id":{"$oid":"67aa8de54af902a85137544b"},"dataset_num":50,"meta_features":[1055.0,6.962243464266207,41.0,3.7376696182833684,2.0,0.0,0.0,0.0,0.0,0.0,0.0,12.0,29.0,0.2926829268292683,0.7073170731707317,0.03886255924170616,0.038126421597793975,25.73170731707317,3.285850400803653,0.33744075829383885,0.6625592417061611,0.5,0.16255924170616112,0.9223486063040569,2.0,8.0,4.5,2.217355782608345,54.0,-0.22651203723867086,808.8716798240384,44.49592560815541,125.75418036429842,-1.7596911761329603,26.807798510823527,3.793236176732872,4.727559619939135,21.0,0.7495922455857551,2.521063897407953,0.8208530805687204,0.8454976303317536,0.6824644549763033,0.7971563981042654,0.7440758293838862,0.814218009478673],"code":"\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport openml\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n# Step 1: Load the dataset\nfrom sklearn.model_selection import train_test_split\ndataset = openml.datasets.get_dataset(dataset_id=1494)\nX, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\n\nnumeric_cols = X.select_dtypes(include=['number']).columns\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\n# Encode categorical columns\nfor col in X.select_dtypes(include='object').columns:\n    X[col] = LabelEncoder().fit_transform(X[col])\n    \n# Step 4: Scale the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\ny = LabelEncoder().fit_transform(y)\nnumpy_dataset = np.column_stack((X, y))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# **Step 2: Convert to PyTorch tensors**\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# **Step 3: Create PyTorch Datasets**\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# **Step 4: Create DataLoaders**\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) \n"}]
